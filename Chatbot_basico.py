import streamlit as st
import requests

# Configurar p√°gina
st.set_page_config(page_title="Chatbot MZF", layout="centered")
st.title("üéæ Chatbot MZF - Torneos de Tenis")
st.markdown("Convers√° con el asistente para inscribirte, informar resultados y consultar sobre el torneo.")

# Token de Hugging Face (debe estar en Secrets)
HF_TOKEN = st.secrets["HF_TOKEN"]

# URL del modelo (puede cambiarse por otro compatible con text2text-generation o text-generation)
API_URL = "https://api-inference.huggingface.co/models/tiiuae/falcon-rw-1b"
headers = {"Authorization": f"Bearer {HF_TOKEN}"}

# Instrucci√≥n base
instruccion_sistema = (
    "Sos un asistente para la organizaci√≥n de un torneo de tenis. "
    "Tu trabajo es inscribir jugadores, registrar resultados, explicar reglas "
    "y ayudar con informaci√≥n sobre partidos. "
    "Si te dan un marcador, asum√≠ que es un resultado; "
    "si te saludan, salud√° cordialmente; "
    "si te preguntan por partidos, respond√© con claridad. "
    "Ped√≠ el nombre si el usuario a√∫n no se identific√≥. "
    "Reconoc√© frases como 'anotarme', 'me inscribo', 'quiero participar', 'gan√© 6-4', 'juego hoy', etc."
)

# Inicializar historial
if "messages" not in st.session_state:
    st.session_state.messages = []

# Mostrar historial
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# Funci√≥n para consultar el modelo
def query_model(prompt):
    payload = {"inputs": f"Instrucci√≥n: {instruccion_sistema}\nUsuario: {prompt}\nRespuesta:"}
    response = requests.post(API_URL, headers=headers, json=payload)
    response.raise_for_status()
    result = response.json()
    return result[0]["generated_text"].split("Respuesta:")[-1].strip()

# Entrada del usuario
if prompt := st.chat_input("Escrib√≠ tu mensaje..."):
    # Mostrar mensaje del usuario
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Obtener respuesta del modelo
    try:
        assistant_reply = query_model(prompt)
    except Exception as e:
        assistant_reply = f"‚ö†Ô∏è Hubo un error al conectar con el modelo: {e}"

    # Mostrar respuesta
    st.session_state.messages.append({"role": "assistant", "content": assistant_reply})
    with st.chat_message("assistant"):
        st.markdown(assistant_reply)
